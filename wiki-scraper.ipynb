{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metal Album Web Scraper\n",
    "\n",
    "Using the Wikipedia API and its relatively well structured tree, I should be able to easily get enough data to build a basic classifier for various subgenres. A few reasons why Wikipedia was used instead of a more specialist website (e.g. metal-archives):\n",
    "\n",
    "* Ease of use - Wikipedia has a good API, so it makes sense to do so.\n",
    "* Because of the nature of Wikipedia moderation, there is an inherent notability filter so bands who released 1 EP and were never seen again. They probably also have the resources to hire a proper artist for their artwork, so there'll be less... \"noise\" in the dataset. Caveat here being something like black metal where the lo-fi aesthetic is something we do want to pick up on.\n",
    "* Could be replicated for other kinds of music. Is there a difference in the art direction of different subgenres of jazz? Between different subgenres (and eras!) of rap?\n",
    "* A specialist website is more likely to split hairs over crossovers between subgenres. For the purposes of this exercise (and personally, in general), we don't really care that Blind Guardian are influenced by bay-area thrash (and are at danger of being labelled as \"Thrash/Power Metal\") or that the use of orchestras would classify Fleshgod Apocalypse as Symphonic Death Metal -- we only want a few data classes to work with!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import relevant libraries\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import wget\n",
    "from PIL import Image\n",
    "from urllib import request, error\n",
    "from bs4 import BeautifulSoup\n",
    "from typing import List"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heavy Metal Subgenres\n",
    "\n",
    "There are enough Death and Black Metal bands that Wikipedia has split them up into two pages. This is nice as it lets us work with imbalanced classes when our classifier is learning the artwork. Although annoying as it means there's a whole different page layout to scrape over.\n",
    "\n",
    "I would imagine that there will be some difficulty differenciating between Thrash and Death metal, given that the latter was an outgrowth of the former and there is likely to be a lot of overlap in the early 90's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 2: Create a list of URLs to cycle through\n",
    "url_list = [\n",
    "    'https://en.wikipedia.org/wiki/List_of_black_metal_bands,_0-K',\n",
    "    'https://en.wikipedia.org/wiki/List_of_black_metal_bands,_L-Z',\n",
    "    # 'https://en.wikipedia.org/wiki/List_of_thrash_metal_bands',\n",
    "    'https://en.wikipedia.org/wiki/List_of_power_metal_bands',\n",
    "    # 'https://en.wikipedia.org/wiki/List_of_death_metal_bands,_!-K',\n",
    "    # 'https://en.wikipedia.org/wiki/List_of_death_metal_bands,_L-Z',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclusion_lists = {\n",
    "    'List_of_black_metal_bands,_0-K': [\n",
    "        '/wiki/Equilibrium_(band)', 'Falconer_(band)', '/wiki/Finntroll', '/wiki/Sepultura', '/wiki/Skeletonwitch', '/wiki/Sodom_(band)', '/wiki/Sunn_O)))', '/wiki/Wintersun'\n",
    "    ],\n",
    "    'List_of_black_metal_bands,_L-Z': [\n",
    "        '/wiki/Sepultura', '/wiki/Skeletonwitch', '/wiki/Sodom_(band)', '/wiki/Sunn_O)))', '/wiki/Wintersun'\n",
    "    ],\n",
    "    'List_of_thrash_metal_bands': [\n",
    "        '/wiki/3_Inches_of_Blood', '/wiki/Black_Tide', '/wiki/Bullet_for_My_Valentine', '/wiki/Celtic_Frost', '/wiki/Children_of_Bodom', '/wiki/God_Forbid',\n",
    "        '/wiki/The_Haunted_(Swedish_band)', '/wiki/Hellhammer', '/wiki/Iced_Earth', '/wiki/Lamb_of_God_(band)', '/wiki/Machine_Head_(band)',\n",
    "        '/wiki/Nevermore', '/wiki/Pantera', '/wiki/Soulfly', '/wiki/Sepultura', '/wiki/Sylosis', '/wiki/Trivium_(band)'\n",
    "    ],\n",
    "    'List_of_thrash_metal_bands': [\n",
    "        '/wiki/3_Inches_of_Blood', '/wiki/Black_Tide', '/wiki/Bullet_for_My_Valentine', '/wiki/Celtic_Frost', '/wiki/Children_of_Bodom', '/wiki/God_Forbid',\n",
    "        '/wiki/The_Haunted_(Swedish_band)', '/wiki/Hellhammer', '/wiki/Iced_Earth', '/wiki/Lamb_of_God_(band)', '/wiki/Machine_Head_(band)',\n",
    "        '/wiki/Nevermore', '/wiki/Pantera', '/wiki/Soulfly', '/wiki/Sepultura', '/wiki/Sylosis', '/wiki/Trivium_(band)'\n",
    "    ],\n",
    "    'List_of_death_metal_bands,_!-K': [\n",
    "        '/wiki/Akercocke', '/wiki/As_I_Lay_Dying_(band)', '/wiki/Battlelore', '/wiki/Behold..._The_Arctopus', '/wiki/Between_the_Buried_and_Me',\n",
    "        '/wiki/Celtic_Frost', '/wiki/God_Forbid', '/wiki/Born_of_Osiris', '/wiki/Children_of_Bodom',\n",
    "        '/wiki/Cradle_of_Filth', '/wiki/Cynic_(band)', '/wiki/Darkthrone', '/wiki/Hellhammer', '/wiki/Fear_Factory',\n",
    "        '/wiki/Ensiferum', '/wiki/Divine_Heresy', '/wiki/DevilDriver', '/wiki/Sepultura', '/wiki/Sylosis', '/wiki/Trivium_(band)'\n",
    "    ],\n",
    "    'List_of_death_metal_bands,_L-Z': [\n",
    "        '/wiki/Lamb_of_God_(band)', '/wiki/Meshuggah', '/wiki/Mr._Bungle', '/wiki/My_Dying_Bride', '/wiki/Paradise_Lost_(band)',\n",
    "        '/wiki/Scar_Symmetry', '/wiki/Sepultura', '/wiki/Soilwork', '/wiki/Sonic_Syndicate',\n",
    "        '/wiki/Soulfly', '/wiki/Cynic_(band)', '/wiki/Strapping_Young_Lad', '/wiki/Sylosis'\n",
    "    ],\n",
    "    'List_of_power_metal_bands': [\n",
    "        '/wiki/Children_of_Bodom', '/wiki/Iron_Maiden', '/wiki/Judas_Priest', '/wiki/Machinae_Supremacy', '/wiki/Rainbow_(rock_band)',\n",
    "        '/wiki/Scorpions_(band)', '/wiki/Trauma_(American_band)', '/wiki/X_Japan'\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Create subdirectory hierarchy\n",
    "\n",
    "parent_output_dir = 'data'\n",
    "if not os.path.exists(parent_output_dir):\n",
    "    os.makedirs(parent_output_dir)\n",
    "\n",
    "for url in url_list:\n",
    "    # Extract the subgenre using regex\n",
    "    subgenre = re.search(r'List_of_(.+)_bands', url.split('/')[-1]).group(1)\n",
    "\n",
    "    # Create a subfolder for each subgenre\n",
    "    output_dir = os.path.join(parent_output_dir, subgenre)\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Band Names\n",
    "\n",
    "Have to allow for two different formats, the first of which you have to navigate a table for and requires a few nested loops which is annoying. Beyond that its quite simple, the other format is just a series of h2 or h3 (depending on the page!) elements immediately followed by a ul elem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_band_names(url: str) -> List[str]:\n",
    "\n",
    "    html = request.urlopen(url)\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    tables = soup.find_all('table', {\"class\": \"wikitable\"})\n",
    "\n",
    "    band_names = []\n",
    "    \n",
    "    # There seem to be two formats for these lists, one in table form and the other in list form.\n",
    "    # Here is the code for the table format:\n",
    "    for table in tables:\n",
    "        for row in table.find_all('tr'):\n",
    "            if first_td := row.find('td'):\n",
    "                a_element = first_td.find('a')\n",
    "                if a_element and a_element.has_attr('title'):\n",
    "                    band_names.append(a_element['href'])\n",
    "\n",
    "    # If the wiki page is in list form, band_names will return []\n",
    "    if band_names == []:\n",
    "        lists = soup.find_all('table', {\"class\": \"multicol\", \"role\": \"presentation\"})[0]\n",
    "        for header in lists.findChildren([\"h2\", \"h3\"], recursive = True):\n",
    "            band_names.extend([\n",
    "                a['href'] for a in header.find_all_next('ul')[0].findChildren(['a']) if a and a.has_attr('title')\n",
    "            ])\n",
    "\n",
    "    return band_names\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Album Names\n",
    "\n",
    "Much like the band lists themselves, whereas most are in list form, some are in table form. Fortunately the \"Discography\" section has a html id which seems to be pretty uniformly followed by some series of `<ul>` elements (sometimes in a div, sometimes not). Can revisit this situation later if I don't have enough data, but as the first list always seems to be albums (as opposed to singles, live albums etc), I can cut off at that for simplicity. Some other good reasons for this (your first EP might not have any art at all, for example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_album_names(band: str) -> List[str]:\n",
    "    band_discography = []\n",
    "\n",
    "    try:\n",
    "        html = request.urlopen(f\"https://en.wikipedia.org{band}\")\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "    except error.HTTPError :\n",
    "        return band_discography\n",
    "    \n",
    "    album_ul = soup.find_all('span', {\"id\": \"Discography\"})\n",
    "\n",
    "    if len(album_ul) > 0:\n",
    "        album_ul = album_ul[0].find_all_next(\"ul\")\n",
    "    if len(album_ul) > 0:\n",
    "        album_ul = album_ul[0]\n",
    "\n",
    "    try:\n",
    "        band_discography.extend([\n",
    "            a['href'] for a in album_ul.findChildren('a', recursive=True) if a.has_attr('title')\n",
    "        ])\n",
    "    except AttributeError:\n",
    "        return []\n",
    "\n",
    "    return band_discography\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Album Artwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_featured_image_url(wikipedia_url: str) -> str:\n",
    "    page_title = wikipedia_url.split(\"/\")[-1]\n",
    "    WIKI_REQUEST = f'https://en.wikipedia.org/w/api.php?action=query&prop=images&titles={page_title}&format=json'\n",
    "\n",
    "    try:\n",
    "        response = request.urlopen(WIKI_REQUEST)\n",
    "        data = json.loads(response.read().decode())\n",
    "    except (error.HTTPError, ValueError):\n",
    "        return 'None'\n",
    "\n",
    "    if 'query' not in data:\n",
    "        return 'None'\n",
    "\n",
    "    page_id = list(data['query']['pages'].keys())[0]\n",
    "    page_data = data['query']['pages'][page_id]\n",
    "\n",
    "    if 'images' in page_data:\n",
    "        image_filenames = [img['title'] for img in page_data['images'] if not img['title'].startswith('File:Wiki')]\n",
    "\n",
    "        if image_filenames:\n",
    "            image_title = image_filenames[0].replace(' ', '_')\n",
    "            image_info_request = f'https://en.wikipedia.org/w/api.php?action=query&prop=imageinfo&iiprop=url&titles={image_title}&format=json'\n",
    "\n",
    "            try:\n",
    "                img = request.urlopen(image_info_request)\n",
    "                response = img.read()\n",
    "                image_data = json.loads(response.decode())\n",
    "\n",
    "            except (error.HTTPError, ValueError):\n",
    "                return 'None'\n",
    "\n",
    "            image_id = list(image_data['query']['pages'].keys())[0]\n",
    "            image_info = image_data.get('query', {}).get('pages', {}).get(image_id, {}).get('imageinfo')\n",
    "\n",
    "            if not image_info:\n",
    "                return 'None'\n",
    "\n",
    "            image_url = image_info[0]['url']\n",
    "\n",
    "            return image_url\n",
    "    return 'None'\n",
    "\n",
    "\n",
    "def save_image(url:str, subgenre:str):\n",
    "\n",
    "    def clean_non_album_images(path: str) -> bool:\n",
    "        # Getting the image and checking its dimensions.\n",
    "        img = Image.open(path)\n",
    "        width, height = img.size\n",
    "\n",
    "        if not 0.9 <= width / height <= 1.1:\n",
    "            os.remove(os.path.join(path))\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    try:\n",
    "        subdir = f'data/{subgenre}'\n",
    "        image_path = f\"{subdir}/{url.split('/')[-1]}\"\n",
    "        wget.download(url, image_path)\n",
    "        \n",
    "        if clean_non_album_images(path = image_path):\n",
    "            pass\n",
    "        else:\n",
    "            print(f'Image saved to {image_path}.')\n",
    "\n",
    "    except error.HTTPError:\n",
    "        pass\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop through functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image saved to data/black_metal/1349_-_Liberation.jpg.\n",
      "Image saved to data/black_metal/1349_Beyond_The_Apocalypse.jpg.\n",
      "Image saved to data/black_metal/1349_-_BlackFlame.jpg.\n",
      "Image saved to data/black_metal/1349_-_Demonoir.jpg.\n",
      "Image saved to data/black_metal/1349Cauldron.png.\n",
      "Image saved to data/black_metal/AbbathCover.png.\n",
      "Image saved to data/black_metal/Abigail_Williams_-_In_the_Shadow_of_a_Thousand_Suns.jpg.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[420], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[39mfor\u001b[39;00m album \u001b[39min\u001b[39;00m get_album_names(band\u001b[39m=\u001b[39mband):\n\u001b[0;32m---> 25\u001b[0m     album_url \u001b[39m=\u001b[39m get_featured_image_url(wikipedia_url\u001b[39m=\u001b[39;49malbum)\n\u001b[1;32m     27\u001b[0m     \u001b[39mif\u001b[39;00m album_url \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mNone\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m album_url\u001b[39m.\u001b[39mlower()[\u001b[39m-\u001b[39m\u001b[39m3\u001b[39m:] \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mjpg\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mpng\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m     28\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[419], line 25\u001b[0m, in \u001b[0;36mget_featured_image_url\u001b[0;34m(wikipedia_url)\u001b[0m\n\u001b[1;32m     22\u001b[0m image_info_request \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mhttps://en.wikipedia.org/w/api.php?action=query&prop=imageinfo&iiprop=url&titles=\u001b[39m\u001b[39m{\u001b[39;00mimage_title\u001b[39m}\u001b[39;00m\u001b[39m&format=json\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     24\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m     img \u001b[39m=\u001b[39m request\u001b[39m.\u001b[39;49murlopen(image_info_request)\n\u001b[1;32m     26\u001b[0m     response \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39mread()\n\u001b[1;32m     27\u001b[0m     image_data \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mloads(response\u001b[39m.\u001b[39mdecode())\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.8/Frameworks/Python.framework/Versions/3.10/lib/python3.10/urllib/request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m     opener \u001b[39m=\u001b[39m _opener\n\u001b[0;32m--> 216\u001b[0m \u001b[39mreturn\u001b[39;00m opener\u001b[39m.\u001b[39;49mopen(url, data, timeout)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.8/Frameworks/Python.framework/Versions/3.10/lib/python3.10/urllib/request.py:519\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    516\u001b[0m     req \u001b[39m=\u001b[39m meth(req)\n\u001b[1;32m    518\u001b[0m sys\u001b[39m.\u001b[39maudit(\u001b[39m'\u001b[39m\u001b[39murllib.Request\u001b[39m\u001b[39m'\u001b[39m, req\u001b[39m.\u001b[39mfull_url, req\u001b[39m.\u001b[39mdata, req\u001b[39m.\u001b[39mheaders, req\u001b[39m.\u001b[39mget_method())\n\u001b[0;32m--> 519\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_open(req, data)\n\u001b[1;32m    521\u001b[0m \u001b[39m# post-process response\u001b[39;00m\n\u001b[1;32m    522\u001b[0m meth_name \u001b[39m=\u001b[39m protocol\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m_response\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.8/Frameworks/Python.framework/Versions/3.10/lib/python3.10/urllib/request.py:536\u001b[0m, in \u001b[0;36mOpenerDirector._open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n\u001b[1;32m    535\u001b[0m protocol \u001b[39m=\u001b[39m req\u001b[39m.\u001b[39mtype\n\u001b[0;32m--> 536\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_chain(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle_open, protocol, protocol \u001b[39m+\u001b[39;49m\n\u001b[1;32m    537\u001b[0m                           \u001b[39m'\u001b[39;49m\u001b[39m_open\u001b[39;49m\u001b[39m'\u001b[39;49m, req)\n\u001b[1;32m    538\u001b[0m \u001b[39mif\u001b[39;00m result:\n\u001b[1;32m    539\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.8/Frameworks/Python.framework/Versions/3.10/lib/python3.10/urllib/request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[39mfor\u001b[39;00m handler \u001b[39min\u001b[39;00m handlers:\n\u001b[1;32m    495\u001b[0m     func \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 496\u001b[0m     result \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    497\u001b[0m     \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    498\u001b[0m         \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.8/Frameworks/Python.framework/Versions/3.10/lib/python3.10/urllib/request.py:1391\u001b[0m, in \u001b[0;36mHTTPSHandler.https_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhttps_open\u001b[39m(\u001b[39mself\u001b[39m, req):\n\u001b[0;32m-> 1391\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdo_open(http\u001b[39m.\u001b[39;49mclient\u001b[39m.\u001b[39;49mHTTPSConnection, req,\n\u001b[1;32m   1392\u001b[0m         context\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_context, check_hostname\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_hostname)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.8/Frameworks/Python.framework/Versions/3.10/lib/python3.10/urllib/request.py:1352\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1350\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m err: \u001b[39m# timeout error\u001b[39;00m\n\u001b[1;32m   1351\u001b[0m         \u001b[39mraise\u001b[39;00m URLError(err)\n\u001b[0;32m-> 1352\u001b[0m     r \u001b[39m=\u001b[39m h\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[1;32m   1353\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m   1354\u001b[0m     h\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.8/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py:1374\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1372\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1373\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1374\u001b[0m         response\u001b[39m.\u001b[39;49mbegin()\n\u001b[1;32m   1375\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n\u001b[1;32m   1376\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.8/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[39m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n\u001b[1;32m    320\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.8/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_status\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadline(_MAXLINE \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m), \u001b[39m\"\u001b[39m\u001b[39miso-8859-1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(line) \u001b[39m>\u001b[39m _MAXLINE:\n\u001b[1;32m    281\u001b[0m         \u001b[39mraise\u001b[39;00m LineTooLong(\u001b[39m\"\u001b[39m\u001b[39mstatus line\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.8/Frameworks/Python.framework/Versions/3.10/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    706\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.8/Frameworks/Python.framework/Versions/3.10/lib/python3.10/ssl.py:1274\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1271\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1272\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1273\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[0;32m-> 1274\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[1;32m   1275\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1276\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.8/Frameworks/Python.framework/Versions/3.10/lib/python3.10/ssl.py:1130\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1128\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1129\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1130\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[1;32m   1131\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1132\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def check_for_junk_data(url:str, excl:List) -> bool:\n",
    "    return any(s in url for s in excl)\n",
    "\n",
    "junk = [\n",
    "    '12in-Vinyl-LP-Record-Angle',\n",
    "    '45_record',\n",
    "    '45rpm',\n",
    "    'Logo_in_use',\n",
    "    '12_Inch_Single_BBQ_Band',\n",
    "    '1966_The_Supremes',\n",
    "    'Alternative_Tentacles_Logo',\n",
    "    'Antestor-BoE-2012-2',\n",
    "    'INDIE_LOGO_WHITE_BOX_outline',\n",
    "    'Gummo_Album'\n",
    "]\n",
    "saved_albums = []\n",
    "\n",
    "for genre_list in url_list:\n",
    "    for band in get_band_names(url=genre_list):\n",
    "\n",
    "        if band in exclusion_lists[genre_list.split('/')[-1]]:\n",
    "            continue\n",
    "\n",
    "        for album in get_album_names(band=band):\n",
    "            album_url = get_featured_image_url(wikipedia_url=album)\n",
    "\n",
    "            if album_url == \"None\" or album_url.lower()[-3:] not in [\"jpg\", \"png\"]:\n",
    "                continue\n",
    "            \n",
    "            if check_for_junk_data(url=album_url, excl=junk):\n",
    "                continue\n",
    "            \n",
    "            # Deduping\n",
    "            if check_for_junk_data(url=album_url, excl=saved_albums):\n",
    "                continue\n",
    "            saved_albums.append(album_url.split('/')[-1])\n",
    "\n",
    "            subgenre = re.search(r'List_of_(.+)_bands', genre_list.split('/')[-1]).group(1)\n",
    "            save_image(url=album_url, subgenre=subgenre)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "\n",
    "There's probably a few dud images in there, and I will have a quick look through, but an easy win would be to get rid of something that isn't album art. Makes sense to get rid of anything that isn't (roughly) sqaure."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
